@inproceedings{ft-transformer,
  author    = {Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages     = {18932--18943},
  publisher = {Curran Associates, Inc.},
  title     = {Revisiting Deep Learning Models for Tabular Data},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2021/file/9d86d83f925f2149e9edb0ac3b49229c-Paper.pdf},
  volume    = {34},
  year      = {2021}
}

@article{adamw,
  author     = {Ilya Loshchilov and
                Frank Hutter},
  title      = {Fixing Weight Decay Regularization in Adam},
  journal    = {CoRR},
  volume     = {abs/1711.05101},
  year       = {2017},
  url        = {http://arxiv.org/abs/1711.05101},
  eprinttype = {arXiv},
  eprint     = {1711.05101},
  timestamp  = {Mon, 13 Aug 2018 16:48:18 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1711-05101.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{gelu,
  author     = {Dan Hendrycks and
                Kevin Gimpel},
  title      = {Bridging Nonlinearities and Stochastic Regularizers with Gaussian
                Error Linear Units},
  journal    = {CoRR},
  volume     = {abs/1606.08415},
  year       = {2016},
  url        = {http://arxiv.org/abs/1606.08415},
  eprinttype = {arXiv},
  eprint     = {1606.08415},
  timestamp  = {Mon, 13 Aug 2018 16:46:20 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/HendrycksG16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{layernorm,
  title         = {Layer Normalization},
  author        = {Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  year          = {2016},
  eprint        = {1607.06450},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@article{transformer,
  author     = {Ashish Vaswani and
                Noam Shazeer and
                Niki Parmar and
                Jakob Uszkoreit and
                Llion Jones and
                Aidan N. Gomez and
                Lukasz Kaiser and
                Illia Polosukhin},
  title      = {Attention Is All You Need},
  journal    = {CoRR},
  volume     = {abs/1706.03762},
  year       = {2017},
  url        = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint     = {1706.03762},
  timestamp  = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{convolutional,
  author     = {Keiron O'Shea and
                Ryan Nash},
  title      = {An Introduction to Convolutional Neural Networks},
  journal    = {CoRR},
  volume     = {abs/1511.08458},
  year       = {2015},
  url        = {http://arxiv.org/abs/1511.08458},
  eprinttype = {arXiv},
  eprint     = {1511.08458},
  timestamp  = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/OSheaN15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{recurrent,
  author     = {Alex Sherstinsky},
  title      = {Fundamentals of Recurrent Neural Network {(RNN)} and Long Short-Term
                Memory {(LSTM)} Network},
  journal    = {CoRR},
  volume     = {abs/1808.03314},
  year       = {2018},
  url        = {http://arxiv.org/abs/1808.03314},
  eprinttype = {arXiv},
  eprint     = {1808.03314},
  timestamp  = {Sun, 02 Sep 2018 15:01:55 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1808-03314.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{pre-norm,
  author     = {Ruibin Xiong and
                Yunchang Yang and
                Di He and
                Kai Zheng and
                Shuxin Zheng and
                Chen Xing and
                Huishuai Zhang and
                Yanyan Lan and
                Liwei Wang and
                Tie{-}Yan Liu},
  title      = {On Layer Normalization in the Transformer Architecture},
  journal    = {CoRR},
  volume     = {abs/2002.04745},
  year       = {2020},
  url        = {https://arxiv.org/abs/2002.04745},
  eprinttype = {arXiv},
  eprint     = {2002.04745},
  timestamp  = {Sat, 23 Jan 2021 01:14:26 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2002-04745.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@unknown{tabular,
  author = {Grinsztajn, Léo and Oyallon, Edouard and Varoquaux, Gael},
  year   = {2022},
  month  = {07},
  pages  = {},
  title  = {Why do tree-based models still outperform deep learning on tabular data?},
  doi    = {10.48550/arXiv.2207.08815}
}

@inproceedings{ig,
  title     = {Axiomatic Attribution for Deep Networks},
  author    = {Mukund Sundararajan and Ankur Taly and Qiqi Yan},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages     = {3319--3328},
  year      = {2017},
  editor    = {Precup, Doina and Teh, Yee Whye},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  month     = {06--11 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf},
  url       = {https://proceedings.mlr.press/v70/sundararajan17a.html},
  abstract  = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.}
}

@article{pytorch,
  title  = {Automatic differentiation in PyTorch},
  author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year   = {2017}
}