\subsection{All classes vs signal and background only vs fine-tuning}

% Rewrite this in a good scientific way. Main points: 
% 1. Severin has experimented with multiclass and binary formulation
% 2. We have seen that when having multiple classes, the network can extract more information and learn better structure.
% 3. However in doing so it "spends it's resources" also on trying to separate between individual backgrounds
% 4. Instead we would like to use these resources to improve on the signal/background separation


% 1. Severin has experimented with multiclass and binary formulation
Severin has experimented with formulating both the multiclass and binary classification formulations. The multiclass
formulation is the most straightforward approach, where the model is trained to differentiate between all classes
simultaneously. The binary formulation, on the other hand, is a more specialized approach, where the model is trained to
distinguish between signal and background classes only. All the classes except for the signal are treated as background.
This approach is motivated by the fact that the signal and background classes are the most important ones for the
primary task of signal and background discrimination.

% 2. We have seen that when having multiple classes, the network can extract more information and learn better structure.
% 3. However in doing so it "spends it's resources" also on trying to separate between individual backgrounds
Based on our observations, we find that when the model is trained to differentiate between all classes, it exhibits
improved learning capabilities and can potentially extract more information from the input data. However, this approach
also allocates resources towards separating individual background classes, which might not be necessary for the primary
task of signal and background discrimination.

% 4. Instead we would like to use these resources to improve on the signal/background separation
Consequently, we propose an alternative strategy to leverage the model's resources more effectively. We initiate the
training it on all available classes but once the good performance is reached, we switch to the binary formulation.
Practically, it means that we are not penalizing the model for misclassifying the background classes (for example if the
true class is $t\bar{t}W$, and the predicted one is $t\bar{t}Z$, we do not penalize the model for this
misclassification). Doing so allows the model to focus on the primary task of signal and background discrimination.
Thus, the model can learn shared underlying physics first, and then focus on the primary task of signal and background
discrimination.

The result are summarized on \autoref{fig:fine-tuning} which shows the progress on the AUC, and accuracy for
differentiating signal from the background.  We can see that the multiclass formulation performs better than the binary
one. The results are further improved by switching to the binary formulation once the good performance is reached.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{example-image-a}
    \caption{Comparison of the multiclass and binary formulations. The dashed line indicates the point where the model
        switches from the multiclass to the binary formulation. (fine-tuning)}
    \label{fig:fine-tuning}
\end{figure}